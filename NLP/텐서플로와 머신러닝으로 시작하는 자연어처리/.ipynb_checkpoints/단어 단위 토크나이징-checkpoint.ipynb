{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/c6/39b29bc6c6c94298e81624746cc69184c9cf064de24d8c40aa68f9eb8779/spacy-2.0.18-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (27.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 27.6MB 1.4MB/s ta 0:00:012\n",
      "\u001b[?25hCollecting plac<1.0.0,>=0.9.6 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/cd/0e/cdb17db34b3b94d1c1f3404d7ffc6c735c323b7cfbf065ae95f56f12a4a8/murmurhash-1.0.2-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl\n",
      "Collecting preshed<2.1.0,>=2.0.1 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/5a/4b6f2035443e463a326e3a81863f2b4850be76b4538fd4931b1aa63f79b6/preshed-2.0.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (148kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 213kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting regex==2018.01.10 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f4/7146c3812f96fcaaf2d06ff6862582302626a59011ccb6f2833bb38d80f7/regex-2018.01.10.tar.gz (612kB)\n",
      "\u001b[K    100% |████████████████████████████████| 614kB 3.2MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/seungmoo/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages (from spacy) (2.21.0)\n",
      "Collecting ujson>=1.35 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/c4/79f3409bc710559015464e5f49b9879430d8f87498ecdc335899732e5377/ujson-1.35.tar.gz (192kB)\n",
      "\u001b[K    100% |████████████████████████████████| 194kB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6e/c6d1650f09b8b2910f149ec7c51fd2298e0e93a657f4496d4636c0a43675/cymem-2.0.2-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (52kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 5.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /Users/seungmoo/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages (from spacy) (1.16.0)\n",
      "Collecting dill<0.3,>=0.2 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/42/bfe2e0857bc284cbe6a011d93f2a9ad58a22cb894461b199ae72cfef0f29/dill-0.2.9.tar.gz (150kB)\n",
      "\u001b[K    100% |████████████████████████████████| 153kB 2.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting thinc<6.13.0,>=6.12.1 (from spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/00/b2abd484bc4ef86e5c308acc6610e8f2c00c89b94701f42b9cc522ca70a4/thinc-6.12.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (2.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.7MB 2.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/seungmoo/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/seungmoo/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/seungmoo/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/seungmoo/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.11.29)\n",
      "Collecting msgpack<0.6.0,>=0.5.6 (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/b6/9affbea179c3c03a0eb53515d9ce404809a122f76bee8fc8c6ec9497f51f/msgpack-0.5.6.tar.gz (138kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 2.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting tqdm<5.0.0,>=4.10.0 (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 10.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cytoolz<0.10,>=0.9.0 (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f4/9728ba01ccb2f55df9a5af029b48ba0aaca1081bbd7823ea2ee223ba7a42/cytoolz-0.9.0.1.tar.gz (443kB)\n",
      "\u001b[K    100% |████████████████████████████████| 450kB 5.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six<2.0.0,>=1.10.0 in /Users/seungmoo/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages (from thinc<6.13.0,>=6.12.1->spacy) (1.12.0)\n",
      "Collecting msgpack-numpy<0.4.4 (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "  Downloading https://files.pythonhosted.org/packages/ad/45/464be6da85b5ca893cfcbd5de3b31a6710f636ccb8521b17bd4110a08d94/msgpack_numpy-0.4.3.2-py2.py3-none-any.whl\n",
      "Collecting wrapt<1.11.0,>=1.10.0 (from thinc<6.13.0,>=6.12.1->spacy)\n",
      "  Using cached https://files.pythonhosted.org/packages/a0/47/66897906448185fcb77fc3c2b1bc20ed0ecca81a0f2f88eda3fc5a34fc3d/wrapt-1.10.11.tar.gz\n",
      "Collecting toolz>=0.8.0 (from cytoolz<0.10,>=0.9.0->thinc<6.13.0,>=6.12.1->spacy)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/d0/a73c15bbeda3d2e7b381a36afb0d9cd770a9f4adc5d1532691013ba881db/toolz-0.9.0.tar.gz\n",
      "Building wheels for collected packages: regex, ujson, dill, msgpack, cytoolz, wrapt, toolz\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/seungmoo/Library/Caches/pip/wheels/74/17/3f/c77bba99efd74ba1a19862c9dd97f4b6d735e2826721dc00ff\n",
      "  Building wheel for ujson (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/seungmoo/Library/Caches/pip/wheels/28/77/e4/0311145b9c2e2f01470e744855131f9e34d6919687550f87d1\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/seungmoo/Library/Caches/pip/wheels/5b/d7/0f/e58eae695403de585269f4e4a94e0cd6ca60ec0c202936fa4a\n",
      "  Building wheel for msgpack (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/seungmoo/Library/Caches/pip/wheels/f0/02/4c/525b56fce78c415eb8066f6554f9de02792df26b8f882f6d65\n",
      "  Building wheel for cytoolz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/seungmoo/Library/Caches/pip/wheels/88/f3/11/9817b001e59ab04889e8cffcbd9087e2e2155b9ebecfc8dd38\n",
      "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/seungmoo/Library/Caches/pip/wheels/48/5d/04/22361a593e70d23b1f7746d932802efe1f0e523376a74f321e\n",
      "  Building wheel for toolz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/seungmoo/Library/Caches/pip/wheels/f4/0c/f6/ce6b2d1aa459ee97cc3c0f82236302bd62d89c86c700219463\n",
      "Successfully built regex ujson dill msgpack cytoolz wrapt toolz\n",
      "Installing collected packages: plac, murmurhash, cymem, preshed, regex, ujson, dill, msgpack, tqdm, toolz, cytoolz, msgpack-numpy, wrapt, thinc, spacy\n",
      "Successfully installed cymem-2.0.2 cytoolz-0.9.0.1 dill-0.2.9 msgpack-0.5.6 msgpack-numpy-0.4.3.2 murmurhash-1.0.2 plac-0.9.6 preshed-2.0.1 regex-2018.1.10 spacy-2.0.18 thinc-6.12.1 toolz-0.9.0 tqdm-4.31.1 ujson-1.35 wrapt-1.10.11\n"
     ]
    }
   ],
   "source": [
    "!pip3 install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 129kB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /Users/seungmoo/.pyenv/versions/tensorflow/lib/python3.6/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /Users/seungmoo/.pyenv/versions/tensorflow/lib/python3.6/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "paragraph = '''\n",
    "Natural language processing (NLP) is a subfield of computer science, \n",
    "information engineering, and artificial intelligence concerned with the interactions between computers and \n",
    "human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data. \n",
    "Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned \n",
    "with the interactions between computers and human (natural) languages, \n",
    "in particular how to program computers to process and analyze large amounts of natural \n",
    "language data.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nNatural language processing (NLP) is a subfield of computer science, \\ninformation engineering, and artificial intelligence concerned with the interactions between computers and \\nhuman (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.', 'Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned \\nwith the interactions between computers and human (natural) languages, \\nin particular how to program computers to process and analyze large amounts of natural \\nlanguage data.']\n"
     ]
    }
   ],
   "source": [
    "print(sent_tokenize(paragraph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '한글 자연어 처리는 재밌다. 이제부터 열심히 해야지ㅎㅎㅎ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '는', '재밌다', '.', '이제', '부터', '열심히', '해야지', 'ㅎㅎㅎ']\n"
     ]
    }
   ],
   "source": [
    "print(okt.morphs(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '는', '재밌다', '.', '이제', '부터', '열심히', '하다', 'ㅎㅎㅎ']\n"
     ]
    }
   ],
   "source": [
    "print(okt.morphs(text, stem=True)) # 형태소 단위로 나눈 후 어간을 추출함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '자연어', '처리', '이제']\n"
     ]
    }
   ],
   "source": [
    "print(okt.nouns(text)) # 명사 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Adjective': '형용사', 'Adverb': '부사', 'Alpha': '알파벳', 'Conjunction': '접속사', 'Determiner': '관형사', 'Eomi': '어미', 'Exclamation': '감탄사', 'Foreign': '외국어, 한자 및 기타기호', 'Hashtag': '트위터 해쉬태그', 'Josa': '조사', 'KoreanParticle': '(ex: ㅋㅋ)', 'Noun': '명사', 'Number': '숫자', 'PreEomi': '선어말어미', 'Punctuation': '구두점', 'ScreenName': '트위터 아이디', 'Suffix': '접미사', 'Unknown': '미등록어', 'Verb': '동사'}\n"
     ]
    }
   ],
   "source": [
    "print(okt.tagset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '한글 자연어', '한글 자연어 처리', '이제', '자연어', '처리']\n"
     ]
    }
   ],
   "source": [
    "print(okt.phrases(text)) # 어절 단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('한글', 'Noun'), ('자연어', 'Noun'), ('처리', 'Noun'), ('는', 'Josa'), ('재밌다', 'Adjective'), ('.', 'Punctuation'), ('이제', 'Noun'), ('부터', 'Josa'), ('열심히', 'Adverb'), ('해야지', 'Verb'), ('ㅎㅎㅎ', 'KoreanParticle')]\n",
      "['한글/Noun', '자연어/Noun', '처리/Noun', '는/Josa', '재밌다/Adjective', './Punctuation', '이제/Noun', '부터/Josa', '열심히/Adverb', '해야지/Verb', 'ㅎㅎㅎ/KoreanParticle']\n"
     ]
    }
   ],
   "source": [
    "print(okt.pos(text)) # 형태소에 품사태깅\n",
    "print(okt.pos(text, join=True)) # 형태소와 품사를 붙여서 리스트화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.corpus import kolaw # 한국 법률 말뭉치 'constitution.txt'로 저장되어있다.\n",
    "from konlpy.corpus import kobill # 대한민국 국회 의안 말뭉치, 각 id값을 가지는 의안으로 구성돼있고 파일은 '1809890.txt'부터 '1809899.txt'까지로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국헌법\\n\\n유구한 역사와 전통에 '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kolaw.open('constitution.txt').read()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'지방공무원법 일부개정법률안\\n\\n(정의화'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobill.open('1809890.txt').read()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobil = kobill.open('1809890.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>725</th>\n",
       "      <th>726</th>\n",
       "      <th>727</th>\n",
       "      <th>728</th>\n",
       "      <th>729</th>\n",
       "      <th>730</th>\n",
       "      <th>731</th>\n",
       "      <th>732</th>\n",
       "      <th>733</th>\n",
       "      <th>734</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>지방공무원법</td>\n",
       "      <td>일부</td>\n",
       "      <td>개정</td>\n",
       "      <td>법률</td>\n",
       "      <td>안</td>\n",
       "      <td>정의화</td>\n",
       "      <td>의원</td>\n",
       "      <td>대표</td>\n",
       "      <td>발의</td>\n",
       "      <td>의</td>\n",
       "      <td>...</td>\n",
       "      <td>팀</td>\n",
       "      <td>장</td>\n",
       "      <td>정</td>\n",
       "      <td>문</td>\n",
       "      <td>종</td>\n",
       "      <td>예산</td>\n",
       "      <td>분석관</td>\n",
       "      <td>김</td>\n",
       "      <td>태</td>\n",
       "      <td>완</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 735 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0   1   2   3   4    5   6   7   8   9   ... 725 726 727 728 729 730  \\\n",
       "0  지방공무원법  일부  개정  법률   안  정의화  의원  대표  발의   의 ...   팀   장   정   문   종  예산   \n",
       "\n",
       "   731 732 733 734  \n",
       "0  분석관   김   태   완  \n",
       "\n",
       "[1 rows x 735 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(okt.nouns(kobil)).T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "kolaw = kolaw.open('constitution.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3882"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(okt.nouns(kolaw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
