{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Our hypothesis XW + b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# Minimize (Gradient descent)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3396367 [1.1039743] [1.2084503]\n",
      "20 0.0008826933 [0.98141396] [1.1692866]\n",
      "40 0.0007648392 [0.98210835] [1.1646043]\n",
      "60 0.0006679436 [0.98327774] [1.1603727]\n",
      "80 0.00058331725 [0.98437285] [1.1564189]\n",
      "100 0.00050941523 [0.98539627] [1.152724]\n",
      "120 0.00044488566 [0.9863526] [1.1492714]\n",
      "140 0.00038852153 [0.98724633] [1.1460446]\n",
      "160 0.000339301 [0.9880816] [1.1430291]\n",
      "180 0.00029631116 [0.98886216] [1.140211]\n",
      "200 0.00025877036 [0.9895916] [1.1375775]\n",
      "220 0.00022598414 [0.9902733] [1.1351166]\n",
      "240 0.00019735478 [0.9909103] [1.1328167]\n",
      "260 0.0001723459 [0.9915057] [1.1306671]\n",
      "280 0.00015051161 [0.992062] [1.1286587]\n",
      "300 0.00013144469 [0.99258184] [1.1267818]\n",
      "320 0.00011479255 [0.9930677] [1.1250279]\n",
      "340 0.000100247424 [0.9935217] [1.1233886]\n",
      "360 8.75478e-05 [0.99394596] [1.121857]\n",
      "380 7.645645e-05 [0.9943423] [1.1204259]\n",
      "400 6.6770204e-05 [0.9947128] [1.1190882]\n",
      "420 5.8311834e-05 [0.99505913] [1.117838]\n",
      "440 5.092402e-05 [0.9953827] [1.1166699]\n",
      "460 4.44723e-05 [0.9956851] [1.1155782]\n",
      "480 3.883754e-05 [0.9959677] [1.1145579]\n",
      "500 3.391812e-05 [0.99623173] [1.1136045]\n",
      "520 2.9621757e-05 [0.9964785] [1.1127136]\n",
      "540 2.5867887e-05 [0.9967091] [1.111881]\n",
      "560 2.259143e-05 [0.99692464] [1.1111029]\n",
      "580 1.972981e-05 [0.99712604] [1.110376]\n",
      "600 1.7231028e-05 [0.99731416] [1.1096965]\n",
      "620 1.5047835e-05 [0.99749005] [1.1090615]\n",
      "640 1.3140891e-05 [0.99765444] [1.108468]\n",
      "660 1.1476324e-05 [0.99780804] [1.1079135]\n",
      "680 1.0022558e-05 [0.9979516] [1.1073953]\n",
      "700 8.753543e-06 [0.99808574] [1.1069111]\n",
      "720 7.643838e-06 [0.9982111] [1.1064584]\n",
      "740 6.6757866e-06 [0.9983282] [1.1060355]\n",
      "760 5.829895e-06 [0.9984377] [1.1056403]\n",
      "780 5.0912213e-06 [0.99854] [1.1052707]\n",
      "800 4.446243e-06 [0.99863565] [1.1049255]\n",
      "820 3.883032e-06 [0.998725] [1.104603]\n",
      "840 3.390666e-06 [0.9988085] [1.1043016]\n",
      "860 2.9610635e-06 [0.9988866] [1.1040198]\n",
      "880 2.5862378e-06 [0.9989594] [1.1037565]\n",
      "900 2.2585868e-06 [0.9990276] [1.1035105]\n",
      "920 1.972339e-06 [0.9990913] [1.1032804]\n",
      "940 1.7221919e-06 [0.9991508] [1.1030656]\n",
      "960 1.5043406e-06 [0.9992065] [1.1028647]\n",
      "980 1.3133417e-06 [0.9992584] [1.1026772]\n",
      "1000 1.1472412e-06 [0.999307] [1.102502]\n",
      "1020 1.0019473e-06 [0.99935234] [1.1023381]\n",
      "1040 8.750494e-07 [0.9993948] [1.102185]\n",
      "1060 7.640393e-07 [0.9994344] [1.1020418]\n",
      "1080 6.6728427e-07 [0.9994715] [1.1019081]\n",
      "1100 5.828915e-07 [0.99950606] [1.1017832]\n",
      "1120 5.089902e-07 [0.9995384] [1.1016663]\n",
      "1140 4.4459966e-07 [0.99956864] [1.1015574]\n",
      "1160 3.8811064e-07 [0.99959683] [1.1014553]\n",
      "1180 3.3913693e-07 [0.99962324] [1.1013601]\n",
      "1200 2.9614648e-07 [0.99964786] [1.101271]\n",
      "1220 2.5864e-07 [0.999671] [1.1011878]\n",
      "1240 2.2583731e-07 [0.9996925] [1.10111]\n",
      "1260 1.9722047e-07 [0.99971265] [1.1010374]\n",
      "1280 1.7230131e-07 [0.9997314] [1.1009694]\n",
      "1300 1.5045264e-07 [0.999749] [1.100906]\n",
      "1320 1.3135924e-07 [0.99976546] [1.1008466]\n",
      "1340 1.14740224e-07 [0.99978083] [1.1007911]\n",
      "1360 1.00252706e-07 [0.99979514] [1.1007396]\n",
      "1380 8.756613e-08 [0.9998085] [1.1006911]\n",
      "1400 7.644776e-08 [0.999821] [1.100646]\n",
      "1420 6.6810934e-08 [0.99983275] [1.1006038]\n",
      "1440 5.8408432e-08 [0.99984366] [1.1005644]\n",
      "1460 5.097105e-08 [0.9998539] [1.1005274]\n",
      "1480 4.453433e-08 [0.99986345] [1.1004931]\n",
      "1500 3.8903966e-08 [0.9998723] [1.1004608]\n",
      "1520 3.4011443e-08 [0.99988073] [1.1004307]\n",
      "1540 2.9697105e-08 [0.9998885] [1.1004025]\n",
      "1560 2.5969996e-08 [0.9998957] [1.1003762]\n",
      "1580 2.268781e-08 [0.9999025] [1.1003519]\n",
      "1600 1.9792527e-08 [0.9999089] [1.1003287]\n",
      "1620 1.7306343e-08 [0.9999149] [1.1003072]\n",
      "1640 1.51334e-08 [0.9999204] [1.1002873]\n",
      "1660 1.3178715e-08 [0.9999256] [1.1002682]\n",
      "1680 1.157606e-08 [0.99993044] [1.1002512]\n",
      "1700 1.0079714e-08 [0.99993503] [1.1002345]\n",
      "1720 8.8177785e-09 [0.9999392] [1.1002194]\n",
      "1740 7.7077065e-09 [0.99994314] [1.1002051]\n",
      "1760 6.7243606e-09 [0.99994695] [1.1001915]\n",
      "1780 5.9192304e-09 [0.9999503] [1.1001796]\n",
      "1800 5.1555276e-09 [0.99995357] [1.1001676]\n",
      "1820 4.4788067e-09 [0.9999567] [1.1001562]\n",
      "1840 3.94067e-09 [0.9999593] [1.1001467]\n",
      "1860 3.4437222e-09 [0.9999619] [1.1001371]\n",
      "1880 2.9898275e-09 [0.9999645] [1.1001276]\n",
      "1900 2.6315887e-09 [0.9999669] [1.1001197]\n",
      "1920 2.3299094e-09 [0.9999689] [1.1001126]\n",
      "1940 2.035415e-09 [0.9999708] [1.1001054]\n",
      "1960 1.7737989e-09 [0.99997276] [1.1000983]\n",
      "1980 1.5266892e-09 [0.9999747] [1.1000911]\n",
      "2000 1.3361842e-09 [0.99997634] [1.1000854]\n"
     ]
    }
   ],
   "source": [
    "# X and Y data\n",
    "# x_train = [1, 2, 3] feed_dict로 따로 넣어줄 것임\n",
    "# y_train = [1, 2, 3]\n",
    "\n",
    "# Now we can use X and Y in place of x_data and y_data\n",
    "# # placeholders for a tensor that will be always fed using feed_dict\n",
    "#\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Our hypothesis XW + b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize (Gradient descent)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], \\\n",
    "                                         feed_dict={X: [1, 2, 3, 4, 5], Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    # cost, W, b, train을 한 리스트에 전부 넣고 한번에 쓸 수 있음\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.099967]\n",
      "[3.6000261]\n",
      "[2.60005  4.600003]\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "print(sess.run(hypothesis\n",
    "               , feed_dict={X: [5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [2.5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X: [1.5, 3.5]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
